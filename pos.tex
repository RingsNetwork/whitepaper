\documentclass[twocolumn]{article}
\usepackage{color}
\usepackage{cite}
\usepackage{draftwatermark}
\usepackage{multirow}
\usepackage{listings}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{titling}
\usepackage{url}
\usepackage{enumitem}
\usepackage{array}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{abstract}
\usepackage[inkscapeformat=png]{svg}


\usetikzlibrary{shapes,arrows,positioning,patterns,through}
\SetWatermarkText{Preview}
\SetWatermarkScale{1}
\setlength\parskip{.5\baselineskip}

\tikzset{
  dot node/.style={
    shape=circle,
    fill=white,
    draw,
    inner sep=+0pt,
    minimum size=+5mm
  },
  dotdot node/.style 2 args={
    dot node,
    label={[shape=circle,fill=black,outer sep=+0pt,inner sep=+0pt,minimum size=+3mm,name=ddd-#1,#2]center:}
  },
  arc style/.style={
    |<->|,
    shorten >=+-.5\pgflinewidth,
    shorten <=+-.5\pgflinewidth,
  }
}

\author{
  Ryan J. Kung \\ ryankung@ieee.org
}
\title{The dRanking Protocol}

\begin{document}
\twocolumn[
  \begin{@twocolumnfalse}

\maketitle
\begin{abstract}
  This article presents a comprehensive reputation system for monitoring and evaluating the performance of nodes in a structured peer-to-peer (P2P) network. The system aims to foster responsible behavior and deter cheating among network participants.

The reputation system is comprised of two main components: local rankings and global rankings. Local rankings reflect the behavior of each node within its own network, while global rankings provide a comprehensive view of the behavior of all nodes in the entire network. To ensure the system's reliability, it utilizes reward proofs and punishment proofs. Nodes exhibiting good behavior are rewarded, while nodes engaging in undesirable actions are penalized, thus creating an environment where nodes are motivated to act ethically and cheating is discouraged.
  ~\\
  ~\\
\end{abstract}

\end{@twocolumnfalse}
]

\section{Introduction and Motivation}
The reputation system presented in this article aims to address the issue of monitoring node performance and preventing cheating in structured peer-to-peer (P2P) networks. By combining local and global rankings, the system provides a comprehensive evaluation of node behavior. The use of reward and punishment proofs incentivizes responsible behavior and discourages cheating, helping to maintain a healthy and secure network.

The system operates under the assumption of the Byzantine generals problem, where at least 2/3 of the nodes are assumed to be honest, as described in the literature \cite{time}. This helps to ensure the robustness and security of the network, allowing it to provide reliable and efficient services to users. Overall, the proposed reputation system represents a significant step forward in the development of secure and efficient structured P2P networks.

\subsection{Local Ranking}
The ranking protocol used in this system is inspired by Edonkey's Ranking Queue \cite{Edonkey}, and adopts a similar approach for monitoring node performance in the network. The objective is to prevent cheating, denial of service, and to maintain a healthy and secure network.

The system includes a mutual scoring system among nodes, which forms the basis of the measurement and local ranking system. The measurement system considers multiple metrics, such as the success rate of sent requests, the validity rate of received requests, and the total number of successful interactions. These metrics provide a comprehensive evaluation of a node's behavior and reliability.

By having each node maintain the scores of surrounding nodes independently, the system creates a decentralized and distributed local ranking system. This approach allows for a more accurate and comprehensive evaluation of node behavior and reliability, as it takes into account observations from multiple nodes in the network.

\subsection{Global Ranking}
The local rankings are used to generate the global ranking through a random sampling method. The random sampling method is based on a decentralized random number oracle, which ensures the fairness and impartiality of the global ranking. The use of a decentralized random number oracle helps to prevent any biases or manipulations in the ranking, ensuring that nodes are evaluated objectively and accurately.

The dRanking protocol implements the transformation from local ranking to global ranking through a four-phase random sampling procedure.

In the first phase, a random seed is generated to ensure the randomness of the sampling procedure and is typically generated by a decentralized oracle to eliminate centralization and bias.

In the second phase, the sampling targets are determined based on the local rankings and the random seed, using a systematic sampling algorithm.

In the third phase, the sample is selected from the local rankings based on the determined sampling targets, and a lookup algorithm is used to find the closest node to the target and provide proof of proximity using Bloom filters.

In the fourth phase, the validity of the sampling results is confirmed through a Kolmogorov-Smirnov (K-S) test to determine if the data is normally distributed. The K-S test compares the empirical cumulative distribution function of the data with the theoretical cumulative distribution function of the normal distribution, and returns a test statistic and a decision on the normality of the data.


\subsection{Reputation}

The ranking protocol uses the reputation system to incentivize and ensure fair local and global rankings. The global ranking is generated through fair random sampling of the local ranking.

The reputation system rewards nodes for good behavior and punishes nodes for bad behavior. This helps to incentivize nodes to behave properly and discourage cheating. The reputation system is designed to maintain a healthy and robust network by promoting fair and honest behavior among nodes.

\section{Related Work}

The edonkey Ranking Queue is a well-known mechanism in the peer-to-peer network community for evaluating node performance. The Rings network adopts a similar approach to the edonkey Ranking Queue to implement its local ranking system.

One relevant work is the eDonkey network, which uses the edonkey Ranking Queue as its mechanism for monitoring node performance. The eDonkey network was one of the earliest peer-to-peer networks to use a mutual scoring system among nodes to prevent cheating or denial of service.

Another related work is the Bittorrent network, which utilizes a mechanism called "choking" to prevent cheating or denial of service. The Bittorrent network evaluates node performance based on the speed and reliability of data transfers, and nodes that perform poorly are restricted from receiving data from other nodes.

In conclusion, the ranking protocol used in the Rings network draws inspiration from the edonkey Ranking Queue and other related works in the peer-to-peer network field. By using a mutual scoring system among nodes, the Rings network aims to provide a secure and efficient peer-to-peer network that can accurately evaluate node performance and prevent cheating or denial of service.

\section{Sampling}

The dRanking protocol effectuates a transformation from local ranking to global ranking through a random sampling procedure, which can be decomposed into four phases:

\textbf{1. Generation of a random seed:}

A random seed is generated to guarantee the randomness of the sampling procedure. The random seed is typically generated through a decentralized oracle to ensure a lack of centralization and bias in the generation process.

\textbf{2. Determination of sampling targets:} Sampling targets are determined based on the local rankings and the randomly generated seed.

\begin{algorithm}[htbp]
  \caption{Systematic Sampling}
  \label{samping}
\begin{algorithmic}[1]
\State $K \gets \lfloor \frac{2^n}{2^m} \rfloor$
\State $r \gets$ random number between 0 and 1
\State $s \gets \lfloor K \cdot r \rfloor$
\State Select elements at positions $s, s + K, s + 2K, \dots$
\end{algorithmic}
\end{algorithm}


We use simple Systematic samping algorithm \ref{samping} here, where n is the number of bits in the random number and m is the desired range of the random sample. The final result is a systematic sample of elements within the range (0, $2^m$).

\textbf{3. Sampling process:} The elements in the local ranking are selected as a sample based on the determined sampling targets.

Due to the potentially large number of nodes in a DHT\cite{Chord} network, it may not be possible to exactly locate the target in the sample processing stage. As a result, the sample processing becomes an approximation process, where the DHT network uses a lookup algorithm to find the peer closest to the sample target and provides proof of proximity.

This is because the number of nodes in a DHT network can be extremely large, and it may not be feasible to store information about every node in the network. The lookup algorithm helps to mitigate this issue by finding the closest peer to the sample target, and the proof of proximity helps to ensure that the peer found is indeed close to the target.

\begin{algorithm}[htbp]
  \caption{Proof of Proximity using Bloom Filters\cite{bloom_filter}}
  \label{bloom}
\begin{algorithmic}[1]
\State \textbf{Input:} Target element $x$, Bloom filters $BF_1, BF_2, \dots, BF_n$ of nodes $N_1, N_2, \dots, N_n$ in the DHT network
\State \textbf{Output:} Node $N_i$ with the closest proximity to target element $x$

\State Initialize $max_bits = 0$ and $closest_node = \text{null}$
\For{each node $N_i$ in the DHT network}
\State $bits = \text{count(bits==1) in} BF_i \text{ correspond to } x$
\If{$bits > max_bits$}
\State $max_bits = bits$
\State $closest_node = N_i$
\EndIf
\EndFor
\State \textbf{return} $closest_node$
\end{algorithmic}
\end{algorithm}

We use Bloom filters to provide proof of proximity in a DHT network. By representing the elements stored at each node as a set of bits in a Bloom filter, the proximity of nodes to a target element can be estimated based on the number of common bits in their Bloom filters. The node with the highest number of bits set to 1 in its Bloom filter is considered the closest node to the target element, and the number of common bits can be used as proof of proximity.

Algorithm \ref{bloom} shows how using Bloom filters to provide proof of proximity in a DHT network, This algorithm takes as input the target element $x$ and the Bloom filters of the nodes in the DHT network. It counts the number of bits set to 1 in each Bloom filter that correspond to the target element, and selects the node with the highest number of bits set to 1 as the node with the closest proximity to the target element. The output is the node with the closest proximity to the target element, which can be used as proof of proximity.

\textbf{4. Validation of sampling results:} The sampling results are validated to confirm their representativeness of the true order of elements in the queue.

We use Kolmogorov-Smirnov(K-S) test to check the result data of sampling is normally distributed. The KS test works by comparing the empirical cumulative distribution function (CDF) of the data with the theoretical CDF of the normal distribution. K-S is described as:
Let $F_{n}(x)$ be the empirical cumulative distribution function (CDF) of a sample of size $n$, and let $F(x)$ be the theoretical CDF of the normal distribution. The Kolmogorov-Smirnov test statistic is defined as:

\begin{equation}
D = \sup_{x} \left| F_{n}(x) - F(x) \right|
\end{equation}

where $\sup$ represents the supremum, or the least upper bound. The value of $D$ measures the maximum difference between the empirical and theoretical CDFs, and is used to determine whether the data is normally distributed.

The null hypothesis of the KS test is that the data is normally distributed, and the alternative hypothesis is that the data is not normally distributed. The test statistic $D$ is compared to critical values from the KS distribution to determine whether to reject or fail to reject the null hypothesis. If the test statistic is greater than the critical value, the null hypothesis is rejected, and the data is considered not to be normally distributed.

And the algorithm can be present as \ref{ks}

\begin{algorithm}[htbp]
\caption{Kolmogorov-Smirnov Test}
\begin{algorithmic}[1]
\State \textbf{Input:} Sample data $x_1, x_2, \dots, x_n$
\State \textbf{Output:} Test statistic $D$ and decision on normality of data

\State Calculate the empirical cumulative distribution function (CDF) $F_{n}(x)$ for the sample data
\State Calculate the theoretical cumulative distribution function (CDF) $F(x)$ for the normal distribution
\State Calculate the test statistic $D$ using the formula:
\begin{equation}
D = \sup_{x} \left| F_{n}(x) - F(x) \right|
\end{equation}
\State Compare the test statistic $D$ to critical values from the KS distribution
\If{$D \leq critical_value$}
\State \textbf{return} "Data is normally distributed", $D$
\Else
\State \textbf{return} "Data is not normally distributed", $D$
\EndIf
\end{algorithmic}
\end{algorithm}

This algorithm calculates the empirical and theoretical CDFs for the sample data and the normal distribution, and calculates the test statistic $D$ as the maximum difference between the empirical and theoretical CDFs. The test statistic is then compared to critical values from the KS distribution to determine whether the data is normally distributed or not. The algorithm returns the test statistic and a decision on the normality of the data.


\section{Gaming}
Let's consider the scenario where individuals are able to repeatedly calculate their global rank until they are satisfied with the outcome. This raises two questions: 1) Will the repeated sampling by the sampler result in a significant increase in network traffic, and 2) Will the sampled individuals be willing to disclose their accurate local rank.
\subsection{Rank maximize}
To optimize the results of the sampling process, the sampler must consider the normal distribution generated by the ranking protocol. As the number of requests made by nodes increases, the maximum value of the normal distribution may decrease. To achieve the highest result possible, the sampler must adjust the number and timing of samplings based on a thorough understanding of the normal distribution.

To determine the most optimal strategy, statistical analysis of the mean and variance of the normal distribution is necessary. This allows the sampler to evaluate different strategies and choose the one that will provide the best results. By performing this analysis, the sampler can optimize the results of the sampling process and achieve the most accurate global ranking.

\begin{align}
  \max_x \quad & n \\
  \text{subject to} \quad & g_i(x) \leq 0, \quad i = 1, \dots, m \\
  & h_j(x) = 0, \quad j = 1, \dots, p
\end{align}

In this model, x is a vector of variables that represent the actions taken by A, n is the objective function to be maximized, $g_i(x)$ represents the inequality constraints, and $h_j(x)$ represents the equality constraints. The goal is to find the values of x that maximize n subject to the constraints.

\subsection{Self-interest}
We use a Guess the Median\cite{game_theory} method to build a game between the sampled nodes, for the sampled objects, the sampled nodes need to have enough motivation to participate, which means rewards, but also means the possibility of cheating. Therefore, we only reward nodes that are close to the Median.

In this game, each player has two strategies: to guess a number that is higher than the median, or to guess a number that is lower than the median. Let's denote the strategy of guessing a number that is higher than the median as H, and the strategy of guessing a number that is lower than the median as L.

The game matrix for Guess the Median would then look like this:

\begin{figure}[htbp]
  \begin{center}
    \begin{tabular}{c|cc} & H & L \\ \hline H & R & S \\ L & T & P \\ \end{tabular}
  \end{center}

\caption{Two player median}
\end{figure}

where R is the reward for both players guessing higher than the median, S is the cost for one player guessing higher and the other guessing lower, T is the cost for both players guessing lower than the median, and P is the reward for one player guessing higher and the other guessing lower.

In this game, the median is considered the Nash Equilibrium, meaning that neither player has an incentive to deviate from their current strategy as long as the other player stays the same. This ensures that both players are motivated to participate and incentivizes honest behavior.

This game can be applied to the nodes in the network to incentivize honest and accurate reporting of their local rankings. The nodes that accurately report their rankings and are close to the median will be rewarded, while nodes that cheat or deviate from the correct rankings will be penalized.

\subsection{Sample weight}
Once nodes obtain the Global Rank, we can calculate their weight based on the Global Rank of the sampled nodes during the sampling process, with higher Global Rank of the sampled objects having a higher weight.

To handle the network's cold start problem, initially, all Global Ranks are set to 0. In order to jumpstart the ranking process, a set of initial high-ranking nodes are introduced to facilitate credit transfer. These nodes are assigned a high Global Rank and their ranking is used as a reference for other nodes to calculate their own Global Rank in subsequent samples. This allows for a gradual increase in the Global Rank of other nodes as they participate in the sampling process and receive rewards based on their proximity to the median.
\subsection{Reward and Slash Proofs}

This way, the system can have both financial incentives and deterrents to maintain the accuracy and reliability of the rankings. The locking mechanism also helps to prevent malicious behavior and cheating, as nodes would have to consider the consequences of their actions before participating in the ranking system. The use of cryptographic signatures and the distributed ledger further enhances the security and transparency of the system. Overall, the combination of rewards, punishments, and locking mechanisms creates a balanced system that incentivizes nodes to contribute to the accuracy and reliability of the ranking system while also deterring malicious behavior.

\section{Economics}

It is generally desirable for Rankings to deflate, as this increases their value. To achieve this, the Rankings need to be made payable, allowing users to use them to purchase services or participate in liquidity staking.

As Sampling continues, the average value of the network's Rankings will increase and the total supply of Rankings will become larger, causing the unit value of Rankings to decrease. To counteract this, the supply within a single Sample Round should be fixed, requiring the results of Sampling to be revealed at a later time. Participants can estimate the quality of their Sample results, but cannot determine their specific value. With a fixed supply, the growth of Rankings becomes linear. As the network grows, obtaining high Rankings becomes more difficult, and so it is suggested that the supply should have a positive correlation with the network size. This means that for each Sample Round, the number of participating nodes $n_i$ and the total supply $s_i$ are established. When $n_i > n_{i-1}$, $s_i$ should be greater than $s_{i-1}$.

\begin{figure}[htbp]
  \label{supply}
\begin{align}
  S_i &= \sum_{i=0}^{i}knc_i\\
  \Delta S &= S_i - S_{i-1} = knc_i\\
  \Delta V &= \frac{knc_i}{S}
 \end{align}
\end{figure}

The figure \ref{supply} illustrates the alteration of the total supply and the value of the token.

And to realize deflation, it is necessary to make the Ranking payable, which typically implies that users are able to utilize it to purchase services or participate in liquidity staking.

Another approach to achieve deflation is to periodically halve the fixed supply of Rankings, similar to how Bitcoin operates. This method ensures a controlled and predictable reduction in the overall supply of Rankings, thereby increasing its unit value over time.


\section{Conclusion}
Overall, the Ranking protocol provides a comprehensive and effective solution for evaluating node performance and preventing cheating or denial of service in structured peer-to-peer networks. By using a mutual scoring system among nodes and a reputation system that incentivizes proper behavior, the Ranking protocol aims to provide a secure and efficient peer-to-peer network.
\bibliographystyle{unsrt}
\bibliography{./cites}
\end{document}
